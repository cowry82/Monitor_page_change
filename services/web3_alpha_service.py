from typing import List, Dict, Any
from datetime import datetime, timedelta
from collections import Counter

from models.database import TokenModel
from models.data_source import (
    RedditDataSource, CoinGeckoDataSource, DexScreenerDataSource,
    TextAnalyzer, AlphaScoreCalculator
)
from config.config import config


class Web3AlphaService:
    """Web3 Alphaè¶‹åŠ¿åˆ†ææœåŠ¡"""
    
    def __init__(self):
        self.db = TokenModel()
        self.narratives = config.get_narratives()
        self.data_sources_config = config.get_data_sources()
        self.weights = config.get_weights()
        
        # åˆå§‹åŒ–æ•°æ®æº
        self.sources = {}
        
        # Redditæ•°æ®æº
        reddit_config = self.data_sources_config.get('reddit', {})
        if reddit_config.get('enabled', True):
            self.sources['reddit'] = RedditDataSource(
                client_id=reddit_config.get('client_id', ''),
                client_secret=reddit_config.get('client_secret', ''),
                user_agent=reddit_config.get('user_agent', 'web3-alpha-tracker')
            )
        
        # CoinGeckoæ•°æ®æº
        coingecko_config = self.data_sources_config.get('coingecko', {})
        if coingecko_config.get('enabled', True):
            self.sources['coingecko'] = CoinGeckoDataSource(
                api_url=coingecko_config.get('api_url', 'https://api.coingecko.com/api/v3')
            )
        
        # DexScreeneræ•°æ®æº
        dexscreener_config = self.data_sources_config.get('dexscreener', {})
        if dexscreener_config.get('enabled', True):
            self.sources['dexscreener'] = DexScreenerDataSource(
                api_url=dexscreener_config.get('api_url', 'https://api.dexscreener.com/latest/dex/search')
            )
        
        # åˆå§‹åŒ–åˆ†æå™¨
        self.text_analyzer = TextAnalyzer(self.narratives)
        self.score_calculator = AlphaScoreCalculator(self.weights)
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("\nğŸš€ Starting Web3 Alpha Radar\n")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self.db.init_db()
        
        # è·å–æ•°æ®
        reddit_texts = []
        cg_tokens = []
        cg_details = {}
        dex_tokens = []
        dex_details = {}
        
        if 'reddit' in self.sources:
            reddit_texts = self._fetch_reddit()
        if 'coingecko' in self.sources:
            cg_tokens, cg_details = self._fetch_coingecko()
        if 'dexscreener' in self.sources:
            dex_tokens, dex_details = self._fetch_dex()
        
        # åˆ†ææ–‡æœ¬
        reddit_tokens, hashtags, narratives = self.text_analyzer.analyze(reddit_texts)
        
        # è®¡ç®—Alphaåˆ†æ•°
        alpha_scores = self.score_calculator.calculate(
            reddit_tokens,
            cg_tokens,
            dex_tokens
        )
        
        # å‡†å¤‡æ•°æ®å¹¶ä¿å­˜
        tokens_data = self._prepare_tokens_data(
            alpha_scores, cg_details, dex_details
        )
        
        self.db.save_tokens(tokens_data)
        self.db.save_narratives(dict(narratives.most_common(20)))
        self.db.save_hashtags(dict(hashtags.most_common(20)))
        
        # æ‰“å°ä»ªè¡¨æ¿
        self._print_dashboard(alpha_scores, narratives, hashtags)
        
        print("\nğŸ’¾ Data saved to database: web3_alpha.db")
        
        return {
            'tokens': tokens_data,
            'narratives': dict(narratives.most_common(20)),
            'hashtags': dict(hashtags.most_common(20))
        }
    
    def _fetch_reddit(self) -> List[str]:
        """è·å–Redditæ•°æ®"""
        if 'reddit' not in self.sources:
            print("ğŸ“¡ Reddit: Skipped (disabled in config)")
            return []
        print("ğŸ“¡ Reddit...")
        texts = self.sources['reddit'].fetch()
        print(f"âœ… Reddit texts: {len(texts)}")
        return texts
    
    def _fetch_coingecko(self) -> tuple:
        """è·å–CoinGeckoæ•°æ®"""
        if 'coingecko' not in self.sources:
            print("ğŸ“¡ CoinGecko: Skipped (disabled in config)")
            return [], {}
        print("ğŸ“¡ CoinGecko...")
        tokens, details = self.sources['coingecko'].fetch()
        print(f"âœ… CoinGecko tokens: {len(tokens)}")
        return tokens, details
    
    def _fetch_dex(self) -> tuple:
        """è·å–DexScreeneræ•°æ®"""
        if 'dexscreener' not in self.sources:
            print("ğŸ“¡ DexScreener: Skipped (disabled in config)")
            return [], {}
        print("ğŸ“¡ DexScreener...")
        tokens, details = self.sources['dexscreener'].fetch()
        print(f"âœ… Dex tokens: {len(tokens)}")
        return tokens, details
    
    def _prepare_tokens_data(self, alpha_scores: Counter, 
                          cg_details: Dict[str, Dict[str, str]],
                          dex_details: Dict[str, Dict[str, str]]) -> List[Dict[str, Any]]:
        """å‡†å¤‡ä»£å¸æ•°æ®"""
        tokens_data = []
        max_score = max(alpha_scores.values()) if alpha_scores else 1
        
        for rank, (symbol, score) in enumerate(alpha_scores.most_common(50), 1):
            heat_level = int((score / max_score) * 5) if max_score > 0 else 0
            
            token_info = {
                "symbol": symbol,
                "rank": rank,
                "alpha_score": round(score, 2),
                "heat_level": heat_level
            }
            
            # æ·»åŠ è¯¦æƒ…
            if symbol in cg_details:
                token_info["name"] = cg_details[symbol]["name"]
                token_info["icon_url"] = cg_details[symbol]["icon_url"]
            elif symbol in dex_details:
                token_info["name"] = dex_details[symbol]["name"]
                token_info["icon_url"] = dex_details[symbol]["icon_url"]
            
            tokens_data.append(token_info)
        
        return tokens_data
    
    def _print_dashboard(self, alpha_tokens: Counter, 
                      narratives: Counter, hashtags: Counter):
        """æ‰“å°ä»ªè¡¨æ¿"""
        print("\n")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ”¥ WEB3 ALPHA TREND RADAR")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        # ä»£å¸
        print("\nğŸ¥‡ MOST DISCUSSED TOKENS (Alpha Score)")
        print("Rank  Token    Score   Heat")
        print("--------------------------------")
        
        max_score = max(alpha_tokens.values()) if alpha_tokens else 1
        
        for i, (t, s) in enumerate(alpha_tokens.most_common(12), 1):
            heat = self._heat_bar(s, max_score)
            print(f"{i:<5} {t:<8} {round(s,2):<7} {heat}")
        
        # å™äº‹
        print("\nğŸš€ HOTTEST WEB3 NARRATIVES")
        print("Rank  Narrative   Mentions")
        print("--------------------------------")
        
        for i, (n, c) in enumerate(narratives.most_common(10), 1):
            print(f"{i:<5} {n:<12} {c}")
        
        # æ ‡ç­¾
        print("\nğŸ“¢ TRENDING HASHTAGS")
        print("--------------------------------")
        
        for tag, c in hashtags.most_common(10):
            print(tag, c)
    
    def _heat_bar(self, score: float, max_score: float) -> str:
        """ç”Ÿæˆçƒ­åº¦æ¡"""
        if max_score == 0:
            return ""
        lvl = int((score / max_score) * 5)
        return "ğŸ”¥" * max(1, lvl)
    
    def get_tokens_by_time_range(self, time_range: str = 'day', 
                              limit: int = 100) -> List[Dict[str, Any]]:
        """æŒ‰æ—¶é—´èŒƒå›´è·å–ä»£å¸æ•°æ®"""
        now = datetime.now()
        
        if time_range == 'hour':
            start_time = now - timedelta(hours=1)
        elif time_range == 'day':
            start_time = now - timedelta(days=1)
        elif time_range == 'week':
            start_time = now - timedelta(weeks=1)
        elif time_range == 'month':
            start_time = now - timedelta(days=30)
        else:
            start_time = now - timedelta(days=1)
        
        start_time_str = start_time.strftime("%Y-%m-%d %H:%M:%S")
        
        return self.db.get_tokens_by_time_range(start_time_str, limit)
    
    def get_narratives(self) -> List[Dict[str, Any]]:
        """è·å–å™äº‹æ•°æ®"""
        return self.db.get_narratives()
    
    def get_hashtags(self) -> List[Dict[str, Any]]:
        """è·å–æ ‡ç­¾æ•°æ®"""
        return self.db.get_hashtags()
